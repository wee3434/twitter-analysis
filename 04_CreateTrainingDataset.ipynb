{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is unlabelled, I needed to develop training data set for learning based classification by my own but with the least manual involvement. I used the lexicon-based classifier, VADER, to annotate the training data for the learning-based classifier, it is expected to maintain the efficiency of lexicon-based approach while harvesting high-performance of learning-based approach. I also expanded existing general purpose sentiment polarity lexica by adding health-relating sentiment polarity lexica by identifying domain-specific words which appear often. Each term was marked into positive and negative manually, aligning with the domain context. Then, I considered the dataset with over or below certain threshold of the score as polar dataset. Furthermore, in order to avoid biasness of the training set, I expanded the training set by labeling manually around 5-10% amount of dataset randomly chosen from each divided interval, which is not considered as polar or neutral data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment import vaderSentiment\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = vaderSentiment.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add our own words with own score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of added Negative Words:  258\n",
      "Number of added Positive Words:  151\n",
      "Number of added Ngram Words:  158\n"
     ]
    }
   ],
   "source": [
    "with open(\"healthcareDictionary.json\") as f:\n",
    "    dictionary =json.loads(f.read())\n",
    "\n",
    "print(\"Number of added Negative Words: \", len(dictionary.get(\"newNegWord\")))\n",
    "print(\"Number of added Positive Words: \", len(dictionary.get(\"newPosWord\")))\n",
    "print(\"Number of added Ngram Words: \", len(dictionary.get(\"newNgram\")))\n",
    "\n",
    "senti.lexicon.update(dictionary.get(\"newNegWord\"))\n",
    "senti.lexicon.update(dictionary.get(\"newPosWord\"))\n",
    "senti.lexicon.update(dictionary.get(\"newNgram\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ngram = [i.replace(\"_\", \" \") for i in newNgram.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.547, 'pos': 0.453, 'compound': 0.357}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.polarity_scores(\"this is not side_effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# further data processing \n",
    "\n",
    "- I changed emoticon into character, which follows format like :\"smiling_face\":.\n",
    "- In order to catch the emoticon on Vader, I removed \":\" and \"_\" for tokenization.  \n",
    "- change bigram words into with underbar between the word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.read_csv(\"cDMARD without URL Vader classifier ver9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = pd.read_csv(\"bDMARD without URL Vader classifier ver9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold is also used in infrared shielding..coloredglass...certain gold salts,still used4 anti-inflammatories in medicine.?yellows from?! smiling face with smiling eyes  grinning face with sweat  squinting face with tongue  smiling face ️\n",
      "certain gold salts are still used as anti-inflammatories in medicine.\n",
      "#goldfacts certain gold salts are still used as anti-inflammatories in medicine.\n",
      "some gold salts used still as anti-inflammatories in medicine.\n",
      "“: some arthritis medications contain gold salts, which is used as an anti-inflammatory” fancy stuff here  new moon_face  ok hand  dizzy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jennyj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "Ngrams = list(word.replace(\"_\", \" \") for word in dictionary.get(\"newNgram\").keys())\n",
    "\n",
    "ngrams = \"|\".join(Ngrams)\n",
    "\n",
    "for i in range(len(cdf)):\n",
    "    try:\n",
    "        c = cdf.tweet[i].lower()\n",
    "        if re.search(ngrams, temp):\n",
    "            \n",
    "            for word in re.findall(ngrams, temp):\n",
    "                temp = re.sub(word, word.replace(\" \", \"_\"), temp)\n",
    "                \n",
    "        if re.search(\"\\:{0,1}[a-z_-]{1,}\\:\", temp):\n",
    "            for emo in re.findall(\"\\:{0,1}[a-z_-]{1,}\\:\", temp):\n",
    "                temp = temp.replace(emo, re.sub(\"\\:|\\_\", \" \", emo))\n",
    "        cdf.tweet[i] = temp\n",
    "           \n",
    "    except Exception:\n",
    "        print(\"error\", c.tweet[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for tweet in cdf.tweet:\n",
    "    score = senti.polarity_scores(tweet)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cDF_score = pd.DataFrame({\"index\":cdf.index, \"id\":cdf.id, \"user_id\": cdf.user_id, \"tweet\": cdf.tweet, \"score\": scores})\n",
    "cDF_score['polarity']  = [score['compound'] for score in scores]\n",
    "\n",
    "cDF_score.to_csv(\"cDMARD without URL Vader classifier ver9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = []\n",
    "for i, tweet in enumerate(bdf.tweet):\n",
    "    try:\n",
    "        score = senti.polarity_scores(tweet)\n",
    "        scores1.append(score)\n",
    "    except Exception:\n",
    "        print(i)\n",
    "        print(tweet)\n",
    "        scores1.append({'compound': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bDF_score = pd.DataFrame({\"index\":bdf.index, \"id\":bdf.id, \"user_id\": bdf.user_id, \"tweet\": bdf.tweet, \"score\": scores1})\n",
    "\n",
    "bDF_score['polarity']  = [score['compound'] for score in scores1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bDF_score.to_csv(\"bDAMRD without URL Vader classifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.094, 'neu': 0.719, 'pos': 0.188, 'compound': 0.4588}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.polarity_scores(\"first time out of the house properly in almost 3 weeks since the start of my relapse . things are moving up :smiling face  infliximab crohnsdisease\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
